{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# TASK 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def weight_m(u, M, inverse): # use inverse = True when doing inverse Fourier Transform\n",
    "    if inverse == False:\n",
    "        W_m = np.full((M, 1), np.exp((-2 * np.pi * (0 + 1.j) * 1 * u) / M))\n",
    "        for i in range(2, M + 1):\n",
    "            col = np.full((M, 1), np.exp((-2 * np.pi * (0 + 1.j) * i * u) / M), dtype=complex)\n",
    "            W_m = np.concatenate([W_m, col], axis=1)\n",
    "        return W_m\n",
    "    else : # inverse == True\n",
    "        W_m = np.full((M, 1), np.exp((2 * np.pi * (0 + 1.j) * 1 * u) / M))\n",
    "        for i in range(2, M + 1):\n",
    "            col = np.full((M, 1), np.exp((2 * np.pi * (0 + 1.j) * i * u) / M), dtype=complex)\n",
    "            W_m = np.concatenate([W_m, col], axis=1)\n",
    "        return W_m\n",
    "\n",
    "def weight_n(v, N, inverse): # use inverse = True when doing inverse Fourier Transform\n",
    "    if inverse == False:\n",
    "        W_n = np.full((1, N), np.exp((-2 * np.pi * (0 + 1.j) * 1 * v) / N))\n",
    "        for i in range(2, N + 1):\n",
    "            row = np.full((1, N), np.exp((-2 * np.pi * (0 + 1.j) * i * v) / N), dtype=complex)\n",
    "            W_n = np.concatenate([W_n, row], axis=0)\n",
    "        return W_n\n",
    "    else : # inverse == True\n",
    "        W_n = np.full((1, N), np.exp((-2 * np.pi * (0 + 1.j) * 1 * v) / N))\n",
    "        for i in range(2, N + 1):\n",
    "            row = np.full((1, N), np.exp((2 * np.pi * (0 + 1.j) * i * v) / N), dtype=complex)\n",
    "            W_n = np.concatenate([W_n, row], axis=0)\n",
    "        return W_n\n",
    "\n",
    "def image_loader(img_path): # Image loader by passing the image path's parent directory as argument\n",
    "    tmp_img_path_list = os.listdir(img_path)\n",
    "    tmp_img_path_list.sort()\n",
    "    start_img = tmp_img_path_list[-1]\n",
    "    del tmp_img_path_list[-1]\n",
    "    tmp_img_path_list.insert(0, start_img)\n",
    "    # print(tmp_img_path_list)\n",
    "\n",
    "    img_array_list = [] # append the loaded numpy arrays (images) here\n",
    "    for img in tmp_img_path_list:\n",
    "        tmp_path = os.path.join(img_path, img)\n",
    "        img_arr = cv2.imread(tmp_path, cv2.IMREAD_GRAYSCALE) # Load image by using OPEN CV -> as numpy\n",
    "        img_array_list.append(img_arr)\n",
    "    # print(img_array_list)\n",
    "    return img_array_list\n",
    "    \n",
    "\n",
    "# image_loader(img_path)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formula_ft(img, startRow, startCol, M, N):\n",
    "\n",
    "    temp_rows = []\n",
    "        # Crop the image for reference\n",
    "    img = img[startRow: startRow + M, startCol : startCol + N]\n",
    "    for u in range(M): # for each row\n",
    "        for v in range(N): # for each column\n",
    "            W_m = weight_m(u, M, inverse=False)\n",
    "            W_n = weight_n(v, N, inverse=False)\n",
    "            # print(W_m.shape, img.shape, W_n.shape)\n",
    "            temp_res = (W_m @ img) @ W_n # returns m x n\n",
    "            temp_res = np.sum(temp_res)\n",
    "            temp_res = (1/(M * N)) * temp_res * 100000\n",
    "            temp_rows.append(temp_res)\n",
    "    # temp_rows[0] = 0 # WTH\n",
    "    temp_arr = np.multiply(np.array(temp_rows), 1/100000)\n",
    "    result_arr = np.reshape(temp_arr, (-1, N))\n",
    "    ft_val = result_arr\n",
    "\n",
    "    return ft_val\n",
    "\n",
    "def fourier_transform(img, patch_size, refcheck): # get the fourier transform result for each image of the images as list\n",
    "    M, N = patch_size\n",
    "    if img is None:\n",
    "            print('[LOAD FAILURE]')\n",
    "            sys.exit()\n",
    "\n",
    "    if refcheck == True:\n",
    "        startRow = 140\n",
    "        startCol = 276\n",
    "       \n",
    "        # print('M, N', M, N)\n",
    "        ft_val = formula_ft(img, startRow, startCol, M, N)\n",
    "        \n",
    "    else : # if listcheck == false\n",
    "        # img = img / np.max(img)\n",
    "        startRow = 0\n",
    "        startCol = 0\n",
    "        ft_val = formula_ft(img, startRow, startCol, M, N)\n",
    "    \n",
    "    return ft_val\n"
   ]
  },
  {
   "source": [
    "# TASK 2 "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_correlation(ft_val_origin, to_compare, patch_size):\n",
    "    before_inverse = np.multiply(ft_val_origin, np.conj(to_compare)) / np.absolute(np.multiply(ft_val_origin, np.conj(to_compare)))\n",
    "    temp_rows = []\n",
    "    # after_inverse = np.max(np.angle(before_inverse))\n",
    "    M, N = patch_size # given as tuple (auto unboxing)\n",
    "    # Inverse Fourier Transform\n",
    "    for u in tqdm(range(M)):\n",
    "        for v in range(N):\n",
    "            W_m = weight_m(u, M, inverse=True)\n",
    "            W_n = weight_n(v, N, inverse=True)\n",
    "            temp_res = (W_m @ before_inverse) @ W_n # returns m x n\n",
    "            temp_res = np.sum(temp_res)\n",
    "            temp_res = temp_res * 100000\n",
    "            temp_rows.append(temp_res)\n",
    "    temp_result = np.array(temp_rows)\n",
    "    after_inverse = np.reshape(temp_result, (-1, N))\n",
    "    after_inverse = np.max(np.angle(after_inverse)) # Get the phase correlation result\n",
    "    return after_inverse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For parallel processing\n",
    "def getcorrel_from_all_patches(img, ft_res, r_start, c_start, patch_size):\n",
    "        tmp_img = img[r_start:r_start+patch_size[0], c_start:c_start+patch_size[1]] # Get the kernel sliding across the image\n",
    "        tmp_img = fourier_transform(tmp_img, patch_size, refcheck=False)\n",
    "        new_correlation_val = phase_correlation(ft_res, tmp_img, patch_size)\n",
    "        return (new_correlation_val, r_start, c_start)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    img_path = '/home/carpedkm/GitHub/Signals_and_Systems/dataset (1)/'\n",
    "    patch_size = (24, 30)\n",
    "    img_list = image_loader(img_path)\n",
    "    # for cnt, img_ in enumerate(img_list):\n",
    "    #     img_list[cnt] = cv2.equalizeHist(img_)\n",
    "    print('[IMAGE LOAD SUCCESSFUL]')\n",
    "    ft_res = fourier_transform(img_list[0], patch_size, refcheck=True) # this is the FT for the referecne patch\n",
    "    print('[FOURIER TRANSFORM OF THE REFERENCE PATCH SUCCESSFUL]')\n",
    "    # FT Inverse transform\n",
    "    M, N = patch_size\n",
    "    temp_rows = []\n",
    "    ft_res_temp = (np.abs(ft_res) - np.min(np.abs(ft_res))) / (np.max(np.abs(ft_res)) - np.min(np.abs(ft_res)))\n",
    "    ft_res_temp = ft_res_temp.astype(float)\n",
    "    plt.imshow(ft_res_temp)\n",
    "    plt.show()\n",
    "    print('[FOURIER END]')\n",
    "    # Get the inverse fourier transfrom result of the reference patch\n",
    "    for u in range(M):\n",
    "        for v in range(N):\n",
    "            W_m = weight_m(u, M, inverse=True)\n",
    "            W_n = weight_n(v, N, inverse=True)\n",
    "            temp_res = W_m @ ft_res @ W_n\n",
    "            temp_res = np.sum(temp_res)\n",
    "            temp_res = temp_res * 100000\n",
    "            temp_rows.append(temp_res)\n",
    "    temp_result = np.array(temp_rows)\n",
    "    after_inverse = np.reshape(temp_result, (-1, N))\n",
    "    after_inverse = (np.abs(after_inverse) - np.min(np.abs(after_inverse))) / (np.max(np.abs(after_inverse)) - np.min(np.abs(after_inverse)))\n",
    "    after_inverse = after_inverse.astype(float)\n",
    "    plt.imshow(after_inverse)\n",
    "    plt.show()\n",
    "    print('[INVERSE END]')\n",
    "    buffer = patch_size\n",
    "    # for test\n",
    "    max_correl_loc = []\n",
    "    for cnt, img in tqdm(enumerate(img_list)):\n",
    "        r_loc = 0\n",
    "        c_loc = 0\n",
    "        print('[IMAGE', cnt, ']', 'Load start')\n",
    "        phase_correlation_val = 0\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        args = ((elem1, elem2) for elem1 in range(0, img.shape[0] - buffer[0], 8) for elem2 in range(0, img.shape[1] - buffer[1], 10))\n",
    "        phases = Parallel(n_jobs=-1, backend='threading')(delayed(getcorrel_from_all_patches)(img, ft_res, r_start, c_start, patch_size)\n",
    "            for r_start, c_start in args)\n",
    "        phases_dict = {}\n",
    "        for p, r, c in phases:\n",
    "            phases_dict[p] = (r, c)\n",
    "\n",
    "        key_comp = 0\n",
    "        keystore = 0\n",
    "        for key_ in list(phases_dict.keys()):\n",
    "            if key_comp < np.angle(key_):\n",
    "                keystore = key_\n",
    "                key_comp = np.angle(key_)\n",
    "        r_loc, c_loc = phases_dict[keystore]\n",
    "        # for r_start in tqdm(range(0, img.shape[0] - buffer[0], 8)):\n",
    "        #     for c_start in range(0, img.shape[1] - buffer[1], 10):\n",
    "                \n",
    "        #         tmp_img = img[r_start:r_start+patch_size[0], c_start:c_start+patch_size[1]] # Get the kernel sliding across the image\n",
    "        #         tmp_img = fourier_transform(tmp_img, patch_size, refcheck=False)\n",
    "        #         new_correlation_val = phase_correlation(ft_res, tmp_img, patch_size)\n",
    "        #         if phase_correlation_val < new_correlation_val:\n",
    "        #             phase_correlation_val = new_correlation_val\n",
    "        #             r_loc = r_start\n",
    "        #             c_loc = c_start\n",
    "                \n",
    "                # print(phase_correlation_val) # Get the temporary phase_correlation_val\n",
    "        max_correl_loc.append((r_loc, c_loc))\n",
    "        print('LOC :', r_loc, c_loc)\n",
    "        img = cv2.rectangle(img, (c_loc, r_loc), (c_loc + patch_size[1], r_loc + patch_size[0]), color=(0, 0, 255), thickness=2)\n",
    "        plt.imshow(img)\n",
    "        # plt.imshow(img[r_loc:r_loc+patch_size[0], c_loc:c_loc+patch_size[1]])\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "            \n",
    "\n"
   ]
  }
 ]
}